{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ermias.tadesse\\10x\\Rossmann-Sales-Forecasting-ML\\log\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from datetime import datetime\n",
    "import logging\n",
    "os.chdir(r'c:\\Users\\ermias.tadesse\\10x\\Rossmann-Sales-Forecasting-ML\\log')\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='store_sales.log', \n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "print(os.getcwd())  # This prints the current working directory\n",
    "os.chdir(r'c:\\Users\\ermias.tadesse\\10x\\Rossmann-Sales-Forecasting-ML')  # Set the working directory to the project root\n",
    "from src.data_loader import DataLoader\n",
    "os.chdir(r'c:\\Users\\ermias.tadesse\\10x\\Rossmann-Sales-Forecasting-ML')  # Set the working directory to the project root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ermias.tadesse\\10x\\Rossmann-Sales-Forecasting-ML\\src\\data_loader.py:13: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.train = pd.read_csv(f\"{self.data_path}/train.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(data_path='data')\n",
    "train_df, test_df, store_df, sample_submission_df = data_loader.load_data()\n",
    "logging.info(\"Loading train_data, test_data, store_data, and sample_submission_data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "##### Extract features from the Date column.\n",
    "##### Handle categorical columns.\n",
    "##### Handle missing values.\n",
    "##### Scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ermias.tadesse\\AppData\\Local\\Temp\\ipykernel_5848\\1173645131.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Open'].fillna(1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Date' column to datetime\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
    "\n",
    "# Feature engineering from 'Date' column\n",
    "train_df['Year'] = train_df['Date'].dt.year\n",
    "train_df['Month'] = train_df['Date'].dt.month\n",
    "train_df['Day'] = train_df['Date'].dt.day\n",
    "train_df['DayOfWeek'] = train_df['Date'].dt.dayofweek\n",
    "train_df['IsWeekend'] = train_df['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "test_df['Year'] = test_df['Date'].dt.year\n",
    "test_df['Month'] = test_df['Date'].dt.month\n",
    "test_df['Day'] = test_df['Date'].dt.day\n",
    "test_df['DayOfWeek'] = test_df['Date'].dt.dayofweek\n",
    "test_df['IsWeekend'] = test_df['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Example additional feature: 'IsBeginningOfMonth'\n",
    "train_df['IsBeginningOfMonth'] = train_df['Day'].apply(lambda x: 1 if x <= 10 else 0)\n",
    "test_df['IsBeginningOfMonth'] = test_df['Day'].apply(lambda x: 1 if x <= 10 else 0)\n",
    "\n",
    "# Handle missing values in 'Open' column for the test data\n",
    "test_df['Open'].fillna(1, inplace=True)  \n",
    "\n",
    "# Select features to include in the model\n",
    "numeric_features = ['Day', 'Month', 'Year', 'Customers', 'Promo', 'IsWeekend', 'IsBeginningOfMonth']\n",
    "categorical_features = ['Store', 'DayOfWeek', 'StateHoliday', 'SchoolHoliday']\n",
    "\n",
    "# Define the target column for the train data\n",
    "target_column = 'Sales'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Convert the Date column to datetime format.\n",
    "Extract new features from the Date column, such as Year, Month, Day, IsWeekend, and IsBeginningOfMonth.\n",
    "Handle missing values in the Open column for the test dataset.\n",
    "Prepare lists of numeric and categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models with sklearn Pipelines\n",
    "Now we'll set up a pipeline that includes:\n",
    "\n",
    "##### Imputation for missing values.\n",
    "##### Scaling for numerical features.\n",
    "##### One-hot encoding for categorical features.\n",
    "##### A RandomForest Regressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ermias.tadesse\\AppData\\Local\\Temp\\ipykernel_5848\\2383822959.py:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['1' '2' '3' ... '1113' '1114' '1115']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, categorical_features] = X_train[categorical_features].astype(str)\n",
      "C:\\Users\\ermias.tadesse\\AppData\\Local\\Temp\\ipykernel_5848\\2383822959.py:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '4' '4' ... '1' '1' '1']' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, categorical_features] = X_train[categorical_features].astype(str)\n",
      "C:\\Users\\ermias.tadesse\\AppData\\Local\\Temp\\ipykernel_5848\\2383822959.py:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['1' '1' '1' ... '1' '1' '1']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, categorical_features] = X_train[categorical_features].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing for numerical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the model pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Split the train data into features and target\n",
    "X_train = train_df[numeric_features + categorical_features]\n",
    "y_train = train_df[target_column]\n",
    "\n",
    "# Convert categorical features to strings to ensure uniform data types\n",
    "X_train.loc[:, categorical_features] = X_train[categorical_features].astype(str)\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prepare the test data (features only)\n",
    "X_test = test_df[numeric_features + categorical_features]\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model_pipeline.predict(X_test)\n",
    "\n",
    "# Check the predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Pipeline\n",
    "A pipeline is created to preprocess both numeric and categorical features.\n",
    "I define a RandomForestRegressor model to fit the preprocessed data.\n",
    "The pipeline is used to fit the model on the training data and make predictions on the test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
